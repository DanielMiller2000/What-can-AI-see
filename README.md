# What-can-AI-see?

**AI-Powered Visual Assistant for the Visually Impaired**

![AI Eye](src/assets/Homepage-image.jpg)


Welcome to **What-can-AI-see?**, an innovative tool designed to help visually impaired individuals understand their surroundings through advanced AI vision technology. Our platform combines state-of-the-art image recognition with natural language processing to provide clear, accurate descriptions of the visual world.

---

## **About the Project**

**What-can-AI-see?** is an intelligent assistant designed to bridge the gap between visual content and accessibility. It leverages cutting-edge computer vision and natural language processing to provide real-time descriptions of images and surroundings, making the visual world more accessible to everyone.

The system utilizes advanced AI techniques including:

- **Vision Transformers** for comprehensive image analysis
- **Natural Language Generation** for clear, contextual descriptions
- **Real-time Processing** for immediate feedback
- **Voice Interface** for hands-free operation
- **Adaptive Learning** to improve accuracy over time

Unlike generic image recognition tools, **What-can-AI-see?** is specifically designed for accessibility, implementing specialized features:

- Context-aware scene description
- Priority-based object detection
- Natural language responses
- Voice-activated controls
- Real-time processing

---

## Key Features

- **Real-time Image Analysis**
  - Advanced object detection
  - Scene understanding
  - Facial expression recognition
  - Color and pattern detection
- **Voice Interface**
  - Natural language interaction
  - Voice-activated commands
  - Clear audio feedback
- **Accessibility Features**
  - High-contrast interface
  - Screen reader compatibility
  - Customizable feedback
  - Intuitive navigation
- **Performance**
  - Fast response times
  - Accurate descriptions
  - Battery efficient
  - Offline capabilities

---

## **Why Choose What-can-AI-see?**

- **Accessibility:** Designed specifically for visually impaired users
- **Accuracy:** Powered by state-of-the-art AI models
- **Ease of Use:** Simple, intuitive voice interface
- **Privacy:** Local processing of sensitive data
- **Reliability:** Works in various lighting conditions
- **Community:** Growing network of users and supporters

---

## Technologies Used

### Core Technologies

- **Computer Vision**
  - Vision Transformers
  - Object Detection Models
  - Scene Understanding
  - OCR Processing

- **Natural Language Processing**
  - GPT-based text generation
  - Voice recognition
  - Context understanding

### Framework Stack

- **Frontend:** 
  - React
  - Vite
  - CSS3
  - HTML5

- **AI Integration:**
  - TensorFlow.js
  - OpenAI API
  - Web Speech API

- **Deployment:**
  - Cloudflare Pages
  - GitHub Actions

---

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/GregorioBermudez/tryout_WCAS.git
   cd tryout_WCAS
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Run the development server:
   ```bash
   npm run dev
   ```

---

## Contributing
We welcome contributions! Please feel free to submit pull requests or create issues for bugs and feature requests.

---

## Contact

- **GitHub:** [What-can-AI-see? Repository](https://github.com/DanielMiller2000/What-can-AI-see)
- **Twitter:** [@whatcanaisee](https://x.com/whatcanaisee?s=21)

---

**Making the visual world accessible to everyone.**
